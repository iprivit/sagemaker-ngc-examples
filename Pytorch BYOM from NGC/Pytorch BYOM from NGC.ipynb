{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You can download an NVIDIA model from torchhub\n",
    "\n",
    "#### ... and then compress it as a tar.gz file, and use this for deployment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-04-24 15:54:51--  https://api.ngc.nvidia.com/v2/models/nvidia/ssdpyt_fp32/versions/2/files/nvidia_ssdpyt_fp32_190826.pt\n",
      "Resolving api.ngc.nvidia.com (api.ngc.nvidia.com)... 54.71.37.245, 52.27.83.248\n",
      "Connecting to api.ngc.nvidia.com (api.ngc.nvidia.com)|54.71.37.245|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 \n",
      "Location: https://s3.us-west-2.amazonaws.com/prod-model-registry-ngc-bucket/org/nvidia/models/ssdpyt_fp32/versions/2/files/nvidia_ssdpyt_fp32_190826.pt?response-content-disposition=attachment%3B%20filename%3D%22nvidia_ssdpyt_fp32_190826.pt%22&response-content-type=application%2Foctet-stream&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEFAaCXVzLXdlc3QtMiJHMEUCIA7U%2BXJ6mzT8tb8Mo9lUxGOLx8rNi1nemb0LG%2Fo%2FFtPPAiEAsQ26nRd8H5Pnzn6LSdyWyweZaga8RmUNhQ0hx%2BOJiKIqtAMIeRACGgw3ODkzNjMxMzUwMjciDJq4RK1xUSe5HJDxvCqRA1ZFlF2tnV3TPtE%2BRIJsViqDJwCtFD7HEiyKFCoxLgMBI%2F%2FMQnXWxfJmcepE5tYhgCsSHReB560xcqfXAwdOKCIUZS5ZOdeuJoLWCQZ9Q9WDSZmswkAaqVCuqKpTkqGEzNEQaA6EzU7i8xVmH3PbW4nm8lc7%2BHLaDKTtPGnvAg1ZEY67iG4cRFj2eh%2FK%2BKzyanH631Lts0XwBH0XB3iZCvcG123taYgdA5IGKUNArs5G7nAceNLLL8UlYgcwWtCO6ufqvUAXwE7si%2Bk8sOmMRfmOucQCO5q3fVGJiGqEE2cqS7P8gLg6YQf6aTu4JqlKWVgpUhw5Mb8q%2FgD8rllY5yQd4KqbrsYfJdguA%2BTCX78oPqzzXW%2FqNfvTQkd%2BCyuxYuaH2aH0arfXNtpwvd5AVF8FXFA0NcmP3KhYLQRc9%2BqigXXYWO98N%2BCNUvxR9DIDOrrWQ1%2FOcRgcfrsFzr%2BPKhhaaUnZ3OMsZhMUvqvyXvGhN16L6%2Bi%2FAtpiWvJgtNJQXrF2pjEUhBG%2FDzuA331YFuqOMPSLjPUFOusBJZHp2%2FbOA%2BaHULxY5IbRCnOIv2rA1hAVMTKmzveNScheKx35gYKt8Mttq4kF%2FJ6REH9cN8nTFv4aCpGtpRWJ2e2K7sm1jppbiOVhDaScNC4%2B3WwGMLVyoAhjKfQdbuXk%2BdlxFzlSVMKMTUfKqxnQgwoNoXmmzBPKugFSTM7aAUrr4lON%2BTRWXb4uV%2BO2ZZVFCkCVzF5PKaVdK4huSpLdSsQfIc0x3RsbNd%2FpXGhbzZDkdg7SqdyCOxm7cteeGg2KtLR5dxM%2F6%2BWsny2BprI6rd45BNhq6U6Qilmwvi1TpcH4%2FyyM43thXulr1w%3D%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20200424T155452Z&X-Amz-SignedHeaders=host&X-Amz-Expires=3600&X-Amz-Credential=ASIA3PSNVSIZ4SUZT2AM%2F20200424%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Signature=544cb7391a782eb7ac108b152540440f2860a53ba51e9147d9ad2f3f15c99405 [following]\n",
      "--2020-04-24 15:54:52--  https://s3.us-west-2.amazonaws.com/prod-model-registry-ngc-bucket/org/nvidia/models/ssdpyt_fp32/versions/2/files/nvidia_ssdpyt_fp32_190826.pt?response-content-disposition=attachment%3B%20filename%3D%22nvidia_ssdpyt_fp32_190826.pt%22&response-content-type=application%2Foctet-stream&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEFAaCXVzLXdlc3QtMiJHMEUCIA7U%2BXJ6mzT8tb8Mo9lUxGOLx8rNi1nemb0LG%2Fo%2FFtPPAiEAsQ26nRd8H5Pnzn6LSdyWyweZaga8RmUNhQ0hx%2BOJiKIqtAMIeRACGgw3ODkzNjMxMzUwMjciDJq4RK1xUSe5HJDxvCqRA1ZFlF2tnV3TPtE%2BRIJsViqDJwCtFD7HEiyKFCoxLgMBI%2F%2FMQnXWxfJmcepE5tYhgCsSHReB560xcqfXAwdOKCIUZS5ZOdeuJoLWCQZ9Q9WDSZmswkAaqVCuqKpTkqGEzNEQaA6EzU7i8xVmH3PbW4nm8lc7%2BHLaDKTtPGnvAg1ZEY67iG4cRFj2eh%2FK%2BKzyanH631Lts0XwBH0XB3iZCvcG123taYgdA5IGKUNArs5G7nAceNLLL8UlYgcwWtCO6ufqvUAXwE7si%2Bk8sOmMRfmOucQCO5q3fVGJiGqEE2cqS7P8gLg6YQf6aTu4JqlKWVgpUhw5Mb8q%2FgD8rllY5yQd4KqbrsYfJdguA%2BTCX78oPqzzXW%2FqNfvTQkd%2BCyuxYuaH2aH0arfXNtpwvd5AVF8FXFA0NcmP3KhYLQRc9%2BqigXXYWO98N%2BCNUvxR9DIDOrrWQ1%2FOcRgcfrsFzr%2BPKhhaaUnZ3OMsZhMUvqvyXvGhN16L6%2Bi%2FAtpiWvJgtNJQXrF2pjEUhBG%2FDzuA331YFuqOMPSLjPUFOusBJZHp2%2FbOA%2BaHULxY5IbRCnOIv2rA1hAVMTKmzveNScheKx35gYKt8Mttq4kF%2FJ6REH9cN8nTFv4aCpGtpRWJ2e2K7sm1jppbiOVhDaScNC4%2B3WwGMLVyoAhjKfQdbuXk%2BdlxFzlSVMKMTUfKqxnQgwoNoXmmzBPKugFSTM7aAUrr4lON%2BTRWXb4uV%2BO2ZZVFCkCVzF5PKaVdK4huSpLdSsQfIc0x3RsbNd%2FpXGhbzZDkdg7SqdyCOxm7cteeGg2KtLR5dxM%2F6%2BWsny2BprI6rd45BNhq6U6Qilmwvi1TpcH4%2FyyM43thXulr1w%3D%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20200424T155452Z&X-Amz-SignedHeaders=host&X-Amz-Expires=3600&X-Amz-Credential=ASIA3PSNVSIZ4SUZT2AM%2F20200424%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Signature=544cb7391a782eb7ac108b152540440f2860a53ba51e9147d9ad2f3f15c99405\n",
      "Resolving s3.us-west-2.amazonaws.com (s3.us-west-2.amazonaws.com)... 52.218.208.112\n",
      "Connecting to s3.us-west-2.amazonaws.com (s3.us-west-2.amazonaws.com)|52.218.208.112|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 183409492 (175M) [application/octet-stream]\n",
      "Saving to: ‘nvidia_ssdpyt_fp32_190826.pt’\n",
      "\n",
      "nvidia_ssdpyt_fp32_ 100%[===================>] 174.91M  20.3MB/s    in 9.0s    \n",
      "\n",
      "2020-04-24 15:55:01 (19.4 MB/s) - ‘nvidia_ssdpyt_fp32_190826.pt’ saved [183409492/183409492]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://api.ngc.nvidia.com/v2/models/nvidia/ssdpyt_fp32/versions/2/files/nvidia_ssdpyt_fp32_190826.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "with tarfile.open('model.tar.gz', mode='w:gz') as archive:\n",
    "    archive.add('nvidia_ssdpyt_fp32_190826.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "sess = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = sess.default_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpath = sess.upload_data(\n",
    "    path='model.tar.gz', bucket=bucket,\n",
    "    key_prefix='sagemaker-pytorch/input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-497456752804/sagemaker-pytorch/input/model.tar.gz'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting transform_script.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile transform_script.py\n",
    "\n",
    "import torch\n",
    "import os\n",
    "from six import BytesIO\n",
    "import numpy as np\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    model = torch.load(os.path.join(model_dir, 'nvidia_ssdpyt_fp32_190826.pt')\n",
    "    return model\n",
    "                       \n",
    "def input_fn(request_body, request_content_type):\n",
    "    \"\"\"An input_fn that loads a pickled tensor\"\"\"\n",
    "    if request_content_type == 'application/python-pickle':\n",
    "        return torch.load(BytesIO(request_body))\n",
    "    else:\n",
    "        # Handle other content-types here or raise an Exception\n",
    "        # if the content type is not supported.\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch.model import PyTorchModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'modelpath' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-f688f709b4ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m pytorch_model = PyTorchModel(model_data=modelpath, role=role,\n\u001b[0m\u001b[1;32m      2\u001b[0m                              \u001b[0mentry_point\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'transform_script.py'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                              framework_version='1.4.0')\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpredictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpytorch_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeploy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ml.m4.xlarge'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_instance_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'modelpath' is not defined"
     ]
    }
   ],
   "source": [
    "pytorch_model = PyTorchModel(model_data=modelpath, role=role,\n",
    "                             entry_point='transform_script.py',\n",
    "                             framework_version='1.4.0')\n",
    "\n",
    "predictor = pytorch_model.deploy(instance_type='ml.m4.xlarge', initial_instance_count=1, wait=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Also, you can download the model from torchhub with this API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/ec2-user/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /home/ec2-user/.cache/torch/checkpoints/resnet50-19c8e357.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fcab6f7575f455b98605a27acd6a435",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=102502400.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading checkpoint from https://api.ngc.nvidia.com/v2/models/nvidia/ssdpyt_fp32/versions/1/files/nvidia_ssdpyt_fp32_20190225.pt\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "precision = 'fp32'\n",
    "ssd_model = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_ssd', model_math=precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch BYOM from NGC.ipynb  tmp.tar.gz\t\t      transform_script.py\r\n",
      "tmp\t\t\t     transform_script_hub.py  u.item\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Or better, download the model from torch hub on the fly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting transform_script_hub.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile transform_script_hub.py\n",
    "\n",
    "import torch\n",
    "import os\n",
    "from six import BytesIO\n",
    "import numpy as np\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    model = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_ssd', model_math='fp32',map_location='gpu')\n",
    "    return model\n",
    "                       \n",
    "def input_fn(request_body, request_content_type):\n",
    "    return torch.load(BytesIO(request_body))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tmp\n",
      "-----------------!"
     ]
    }
   ],
   "source": [
    "#PyTorchModel requires a non-empty, model_data file\n",
    "from sagemaker.pytorch.model import PyTorchModel\n",
    "from sagemaker import get_execution_role\n",
    "role = get_execution_role()\n",
    "\n",
    "!echo \"tmp content\" > tmp\n",
    "!tar -zcvf ./tmp.tar.gz tmp\n",
    "pytorch_model = PyTorchModel(model_data = 'file://tmp.tar.gz',\n",
    "                             role=role,\n",
    "                             entry_point='./transform_script_hub.py',\n",
    "                             framework_version='1.4.0')\n",
    "\n",
    "predictor = pytorch_model.deploy(instance_type='ml.p3.2xlarge',\n",
    "                                 initial_instance_count=1,\n",
    "                                 endpoint_name='nvidia-ssd-pytorch-gpu2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/ec2-user/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub\n"
     ]
    }
   ],
   "source": [
    "utils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_ssd_processing_utils')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "uris = [\n",
    "    'http://images.cocodataset.org/val2017/000000397133.jpg',\n",
    "    'http://images.cocodataset.org/val2017/000000037777.jpg',\n",
    "    'http://images.cocodataset.org/val2017/000000252219.jpg'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    }
   ],
   "source": [
    "inputs = [utils.prepare_input(uri) for uri in uris]\n",
    "tensor = utils.prepare_tensor(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3, 300, 300)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.cpu().numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import urllib\n",
    "import cv2\n",
    "\n",
    "# METHOD #1: OpenCV, NumPy, and urllib\n",
    "def url_to_image(url):\n",
    "    resp = urllib.request.urlopen(url)\n",
    "    image = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
    "    image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = url_to_image('https://upload.wikimedia.org/wikipedia/commons/2/25/Postmen_Office_Room.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = image.transpose((2, 0, 1)).reshape(1,image.shape[0],image.shape[1],image.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModelError",
     "evalue": "An error occurred (ModelError) when calling the InvokeEndpoint operation: Received server error (500) from model with message \"'NoneType' object has no attribute 'to'\". See https://us-east-1.console.aws.amazon.com/cloudwatch/home?region=us-east-1#logEventViewer:group=/aws/sagemaker/Endpoints/nvidia-ssd-pytorch-gpu2 in account 497456752804 for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModelError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-16c90a52f188>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#tensor.cpu().numpy()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/predictor.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, initial_args, target_model)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mrequest_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_request_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_runtime_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mrequest_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    314\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[1;32m    315\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModelError\u001b[0m: An error occurred (ModelError) when calling the InvokeEndpoint operation: Received server error (500) from model with message \"'NoneType' object has no attribute 'to'\". See https://us-east-1.console.aws.amazon.com/cloudwatch/home?region=us-east-1#logEventViewer:group=/aws/sagemaker/Endpoints/nvidia-ssd-pytorch-gpu2 in account 497456752804 for more information."
     ]
    }
   ],
   "source": [
    "predictor.predict(tensor.cpu()) #tensor.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127.32780612244898"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1197900/(64*3*7*7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm nvidia_ssdpyt_fp32_190826.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
